version: 2

before:
  hooks:
    - go mod tidy
    - go test ./...

builds:
  - id: tokenizer
    main: ./cmd/tokenizer
    binary: tokenizer
    env:
      - CGO_ENABLED=0
    goos:
      - linux
      - darwin
      - windows
      - freebsd
    goarch:
      - amd64
      - arm64
      - arm
    goarm:
      - "6"
      - "7"
    ignore:
      - goos: darwin
        goarch: arm
      - goos: windows
        goarch: arm
      - goos: windows
        goarch: arm64
      - goos: freebsd
        goarch: arm
    ldflags:
      - -s -w
      - -X main.version={{.Version}}
      - -X main.commit={{.ShortCommit}}
      - -X main.buildDate={{.Date}}
      - -X main.goVersion={{.Runtime.Goversion}}
      - -X main.builtBy=goreleaser

archives:
  - id: tokenizer
    ids:
      - tokenizer
    formats:
      - tar.gz
    format_overrides:
      - goos: windows
        formats:
          - zip
    name_template: >-
      {{ .ProjectName }}_
      {{- .Version }}_
      {{- .Os }}_
      {{- if eq .Arch "amd64" }}x86_64
      {{- else if eq .Arch "386" }}i386
      {{- else }}{{ .Arch }}{{ end }}
      {{- if .Arm }}v{{ .Arm }}{{ end }}
    files:
      - LICENSE
      - README.md

checksum:
  name_template: 'checksums.txt'
  algorithm: sha256

snapshot:
  version_template: "{{ incpatch .Version }}-next"

changelog:
  sort: asc
  use: github
  filters:
    exclude:
      - '^docs:'
      - '^test:'
      - '^chore:'
      - Merge pull request
      - Merge branch
  groups:
    - title: 'New Features'
      regexp: '^.*?feat(\([[:word:]]+\))??!?:.+$'
      order: 0
    - title: 'Bug fixes'
      regexp: '^.*?fix(\([[:word:]]+\))??!?:.+$'
      order: 1
    - title: 'Performance improvements'
      regexp: '^.*?perf(\([[:word:]]+\))??!?:.+$'
      order: 2
    - title: Others
      order: 999

release:
  github:
    owner: agentstation
    name: tokenizer
  name_template: "v{{.Version}}"
  header: |
    ## Release v{{.Version}}
    
    ### Installation
    
    #### Homebrew (macOS and Linux)
    ```bash
    brew install agentstation/tap/tokenizer
    ```
    
    #### Download Binary
    Download the appropriate binary for your platform from the assets below.
    
    #### Using Go
    ```bash
    go install github.com/agentstation/tokenizer/cmd/tokenizer@v{{.Version}}
    ```
    
    #### Verify Checksums
    ```bash
    # Download checksums.txt and the binary, then:
    sha256sum -c checksums.txt
    ```

# Homebrew tap configuration
brews:
  - repository:
      owner: agentstation
      name: homebrew-tap
      token: "{{ .Env.HOMEBREW_TAP_TOKEN }}"
    
    # Formula name
    name: tokenizer
    
    # Directory inside the repository
    directory: Formula
    
    # Git commit information
    commit_author:
      name: "GitHub Actions"
      email: "actions@github.com"
    
    commit_msg_template: "Update tokenizer to {{ .Tag }}"
    
    # Homepage
    homepage: "https://github.com/agentstation/tokenizer"
    
    # Description
    description: "High-performance tokenizer implementations in Go with unified CLI"
    
    # License
    license: "MIT"
    
    # Skip upload if version exists
    skip_upload: false
    
    # Use pre-built binaries (bottles) instead of building from source
    download_strategy: CurlDownloadStrategy
    
    # Dependencies
    dependencies:
      - name: go
        type: build
        version: "1.24"
    
    # Custom install block
    install: |
      if build.bottle?
        bin.install "tokenizer"
      else
        # Build from source with version information
        # Note: buildDate is the actual build time (now), not the commit date
        ldflags = %W[
          -s -w
          -X main.version=#{version}
          -X main.commit={{ .ShortCommit }}
          -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
          -X main.goVersion=#{Formula["go"].version}
          -X main.builtBy=homebrew
        ]
        system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
      end
      
      # Install documentation
      doc.install "README.md", "LICENSE", "CLAUDE.md"
      doc.install "llama3/README.md" => "llama3-README.md"
      doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"
      
      # Install examples if they exist
      if Dir.exist?("examples")
        pkgshare.install "examples"
      end
    
    # Test block
    test: |
      # Test version command
      output = shell_output("#{bin}/tokenizer version")
      assert_match version.to_s, output
      assert_match "commit:", output
      assert_match "built:", output
      assert_match "go version:", output
      
      # Test help output
      assert_match "Usage:", shell_output("#{bin}/tokenizer --help")
      assert_match "Available Commands:", shell_output("#{bin}/tokenizer --help")
      
      # Test llama3 subcommand
      assert_match "llama3", shell_output("#{bin}/tokenizer --help")
      assert_match "encode", shell_output("#{bin}/tokenizer llama3 --help")
      
      # Test encoding
      output = shell_output("#{bin}/tokenizer llama3 encode 'Hello, world!'")
      assert_match "128000", output # begin_of_text token
      assert_match "9906", output   # "Hello" token
      assert_match "128001", output # end_of_text token
      
      # Test decoding
      output = shell_output("#{bin}/tokenizer llama3 decode 128000 9906 11 1917 0 128001")
      assert_match "Hello", output
      assert_match "world", output
      
      # Test info command
      output = shell_output("#{bin}/tokenizer llama3 info")
      assert_match "Vocabulary Size: 128256", output
      assert_match "Regular Tokens: 128000", output
      assert_match "Special Tokens: 256", output
      
      # Test piping
      output = pipe_output("#{bin}/tokenizer llama3 encode", "Test input")
      assert_match "128000", output # begin_of_text token
    
    # Custom caveats (simplified from the manual formula)
    caveats: |
      Tokenizer has been installed! ðŸš€

      Quick start:
        tokenizer llama3 encode "Hello, world!"     # Encode text to tokens
        tokenizer llama3 decode 128000 9906 128001  # Decode tokens to text
        tokenizer llama3 info                       # Show tokenizer info
        tokenizer --help                            # Show all commands

      Documentation: https://github.com/agentstation/tokenizer